{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Elo_project_Final_blending",
      "provenance": [],
      "authorship_tag": "ABX9TyMkT6bXz7u6bbO+0Xdgpjxq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zizilnam/Mini_Project_Machine_Learning_Elo_Merchant_Kaggle/blob/main/Elo_project_Final_blending.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxJEIvNUPK0L"
      },
      "source": [
        "# Final Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwe36i8UKVes",
        "outputId": "d1f11efe-0f5c-40bf-8c32-4e6ba331d15c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phrF2XHL_lWG",
        "outputId": "ab0c2cf8-3913-47f8-b4e1-919c4cfee00d"
      },
      "source": [
        "cd/content/drive/MyDrive/KDT/모델링 프로젝트/data/data_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KDT/모델링 프로젝트/data/data_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb_UrGrjOCFZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold, RepeatedKFold, KFold\n",
        "\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import lightgbm as lgb\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, roc_auc_score, log_loss\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "import time\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY5HBkMCOLV0"
      },
      "source": [
        "#https://www.kaggle.com/fabiendaniel/elo-world\n",
        "#Function to load data into pandas and reduce memory usage\n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8sj1oIXPPdZ"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GYxfYS3ObUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbec088-a83c-4ee3-d6b0-3a8b0a73fcf0"
      },
      "source": [
        "train = reduce_mem_usage(pd.read_csv('/content/drive/MyDrive/KDT/모델링 프로젝트/data/train_features_generated.csv', index_col=0))\n",
        "test = reduce_mem_usage(pd.read_csv('/content/drive/MyDrive/KDT/모델링 프로젝트/data/test_features_generated.csv', index_col=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mem. usage decreased to 100.71 Mb (74.7% reduction)\n",
            "Mem. usage decreased to 61.19 Mb (74.7% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBoJHtOUOmOC"
      },
      "source": [
        "with open('low_prob_test_predictions.pkl', 'rb') as f:\n",
        "  test_low_pred = pickle.load(f)\n",
        "\n",
        "with open('low_prob_train_predictions.pkl', 'rb') as f:\n",
        "  train_low_pred = pickle.load(f)\n",
        "\n",
        "with open('high_prob_train_predictions.pkl', 'rb') as f:\n",
        "  train_high_pred = pickle.load(f)\n",
        "\n",
        "with open('high_prob_test_predictions.pkl', 'rb') as f:\n",
        "  test_high_pred = pickle.load(f)\n",
        "\n",
        "#Load the full regression predictions\n",
        "\n",
        "with open('train_predictions_full_regression.pkl', 'rb') as f:\n",
        "  full_regression_train_preds = pickle.load(f)\n",
        "\n",
        "with open('test_predictions_full_regression.pkl', 'rb') as f:\n",
        "  full_regression_test_preds = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGlLrH0VOvxp"
      },
      "source": [
        "train = train.merge(train_low_pred, on = 'card_id', how='left')\n",
        "train = train.merge(train_high_pred, on = 'card_id', how='left')\n",
        "train = train.merge(full_regression_train_preds, on = 'card_id', how='left')\n",
        "\n",
        "test = test.merge(test_low_pred, on = 'card_id', how='left')\n",
        "test = test.merge(test_high_pred, on = 'card_id', how='left')\n",
        "test = test.merge(full_regression_test_preds, on = 'card_id', how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50H9J1u3Owgj"
      },
      "source": [
        "train_target = train['target']\n",
        "test_card_id = test['card_id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MupZKFJhOyvC"
      },
      "source": [
        "columns = ['low_prob_score', 'high_prob_score', 'full_regression_prediction']\n",
        "train = train[columns]\n",
        "test = test[columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECrEUWizO2tp"
      },
      "source": [
        "## Full Blend Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORdc_0NtO5ZJ"
      },
      "source": [
        "BayesianRegression model 으로 모델링 시도합니다.\n",
        "\n",
        "두번째는 RandomforestRegressor: 3.79391600433\n",
        "\n",
        "세번째 Linear Regression: 3.68191541424833\n",
        "\n",
        "네번째 sgdr : 3.96"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj5zDBUGKipj"
      },
      "source": [
        "Random Forest Regressor Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dTamb4zKqAH",
        "outputId": "854d1dae-325e-4d49-c645-efe7f99d4716"
      },
      "source": [
        "alpha = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
        "params = {'alpha': alpha}\n",
        "\n",
        "model=SGDRegressor()\n",
        "random_search = RandomizedSearchCV(model, params, scoring = 'neg_root_mean_squared_error', cv = 5)\n",
        "random_search.fit(train, train_target)\n",
        "random_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.0001}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_rkpFOrO0aR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5daf118-356e-4824-da61-c2d812336e26"
      },
      "source": [
        "folds_stack = KFold(n_splits=5, shuffle=True, random_state=4590)\n",
        "oof = np.zeros(train.shape[0])\n",
        "test_pred = np.zeros(test.shape[0])\n",
        "\n",
        "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train,train_target)):\n",
        "    print(\"fold {}\".format(fold_))\n",
        "    trn_data, trn_y = train.iloc[trn_idx], train_target.iloc[trn_idx]\n",
        "    val_data, val_y = train.iloc[val_idx], train_target.iloc[val_idx]\n",
        "    \n",
        "    clf_3 = SGDRegressor(alpha=0.0001)\n",
        "    clf_3.fit(trn_data, trn_y)\n",
        "    \n",
        "    oof[val_idx] = clf_3.predict(val_data)\n",
        "    test_pred += clf_3.predict(test) / 5\n",
        "    \n",
        "print(\"CV RMSE:\", np.sqrt(mean_squared_error(train_target.values, oof)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0\n",
            "fold 1\n",
            "fold 2\n",
            "fold 3\n",
            "fold 4\n",
            "CV RMSE: 3.7196374501784955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvfF1fvMPTKa"
      },
      "source": [
        "## Kaggle Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcK5sNkYPWR0"
      },
      "source": [
        "kaggle_submission = pd.DataFrame()\n",
        "kaggle_submission['card_id'] = test_card_id\n",
        "kaggle_submission['target'] = test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJJ8b7bvPbsC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "dca5b1f2-c99e-4f64-9a1e-5c5fa2e2a695"
      },
      "source": [
        "kaggle_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>card_id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C_ID_0ab67a22ab</td>\n",
              "      <td>-0.388070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C_ID_130fd0cbdd</td>\n",
              "      <td>1.353149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C_ID_b709037bc5</td>\n",
              "      <td>0.586925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C_ID_d27d835a9f</td>\n",
              "      <td>1.072608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C_ID_2b5e3df5c2</td>\n",
              "      <td>0.454365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123618</th>\n",
              "      <td>C_ID_7a239d2eda</td>\n",
              "      <td>2.506311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123619</th>\n",
              "      <td>C_ID_75ace375ae</td>\n",
              "      <td>0.989641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123620</th>\n",
              "      <td>C_ID_21d56d950c</td>\n",
              "      <td>2.174796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123621</th>\n",
              "      <td>C_ID_6c46fc5a9d</td>\n",
              "      <td>-1.316626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123622</th>\n",
              "      <td>C_ID_87e7979a5f</td>\n",
              "      <td>1.201090</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>123623 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                card_id    target\n",
              "0       C_ID_0ab67a22ab -0.388070\n",
              "1       C_ID_130fd0cbdd  1.353149\n",
              "2       C_ID_b709037bc5  0.586925\n",
              "3       C_ID_d27d835a9f  1.072608\n",
              "4       C_ID_2b5e3df5c2  0.454365\n",
              "...                 ...       ...\n",
              "123618  C_ID_7a239d2eda  2.506311\n",
              "123619  C_ID_75ace375ae  0.989641\n",
              "123620  C_ID_21d56d950c  2.174796\n",
              "123621  C_ID_6c46fc5a9d -1.316626\n",
              "123622  C_ID_87e7979a5f  1.201090\n",
              "\n",
              "[123623 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6qFKd9gPeVJ"
      },
      "source": [
        "kaggle_submission.to_csv('final_blended_model_sgdr2.csv', index=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2fJihxKEELM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}